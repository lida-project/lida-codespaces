{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducing Microsoft LIDA \n",
    "\n",
    "[Microsoft LIDA](https://github.com/microsoft/lida) is an open-source Python library for the _automatic generation of data visualizations and data-faithful infographics_ using Large Language Models.  \n",
    "\n",
    "LIDA is grammar agnostic (will work with any programming language and visualization libraries e.g. matplotlib, seaborn, altair, d3 etc) and works with multiple large language model providers (OpenAI, Azure OpenAI, PaLM, Cohere, Huggingface). \n",
    " * üî¨ | | Read [this paper](https://browse.arxiv.org/pdf/2303.02927.pdf) for more details on the research\n",
    " * üìó | See [this notebook](https://github.com/microsoft/lida/blob/main/notebooks/tutorial.ipynb) for a sample tutorial.\n",
    " * üíª | Check out [this website](https://microsoft.github.io/lida/) for project updates.\n",
    " * ‚≠êÔ∏è | Star [this repo](https://github.com/microsoft/lida) if you like the project.\n",
    " * üìΩ | Watch [this video](https://vimeo.com/820968433) for a quick walkthrough of LIDA in action.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Getting Started: [LIDA on Codespaces](https://github.com/lida-project/lida-codespaces) \n",
    "\n",
    "The [lida-codespaces](https://github.com/lida-project/lida-codespaces) template is set up with \n",
    " - a [dev container](https://containers.dev) configuration that uses\n",
    " - the [Microsoft Universal](https://mcr.microsoft.com/en-us/product/devcontainers/universal/about) container image and \n",
    " - uses `.devcontainer/requirements.txt` to install Python package dependencies including `lida`\n",
    "\n",
    "If you intend to use lida with local huggingface models, you will need the `transformers` library. \n",
    " - this is currently installed post container creation (see `.devcontainer/post-create-command.sh`)\n",
    "\n",
    "This means your development environment is already set for using `lida`. You can just dive straight into writing your applications.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Getting Started: OpenAI/LLM API Keys\n",
    "\n",
    "This requires two things:\n",
    " - an OPENAI_API_KEY set in your environment variables.\n",
    " - the `openai` package installed in the development environment.\n",
    "\n",
    "The second requirement is taken care of for you in the development container. \n",
    "\n",
    "To set the OPENAI_API_KEY you have two options based on where you run the dev container\n",
    " - Using GitHub Codespaces? Then [set this up as a codespaces secret](https://docs.github.com/en/codespaces/managing-your-codespaces/managing-secrets-for-your-codespaces).\n",
    " - Using Docker Desktop? Then copy `.env.copy` into a `.env` file in repo root, and fill in the required LLM keys\n",
    "\n",
    "Once you do this, running the development container will make those environment variables available to your notebooks for use.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Troubleshooting: ModuleNotFoundError\n",
    "\n",
    "When running in a dev container (vs. your own local installed environment) you may encounter this error message:\n",
    "\n",
    "```bash\n",
    "ModuleNotFoundError: No module named '_lzma'\n",
    "```\n",
    "\n",
    "This seems to be a frequently-encountered issue. Python 3.3 and later should provide this module by default - but in some cases the _lzma-dev_ packagte is not installed correctly and the module does not seem to resolve for imports. After multiple trial-and-error runs, the [approach defined in this article](https://support.huawei.com/enterprise/en/doc/EDOC1100289998/db0db8f0/modulenotfounderror-no-module-named-_lzma-) seemed to work to fix the issue.\n",
    "\n",
    "Steps are:\n",
    "\n",
    "1. Install the `liblzma-dev` system dependency first | üëâüèΩ  `sudo apt-get install -y liblzma-dev`\n",
    "2. Install the `lzma` Python module next | üëâüèΩ  `pip3 install backports.lzma`\n",
    "3. Modify the system `lzma.py` file to handle error | üëâüèΩ  `vi /usr/local/python/3.10.8/lib/python3.10/lzma.py`\n",
    "\n",
    "In that file replace:\n",
    "\n",
    "```python\n",
    "from _lzma import *\n",
    "from _lzma import _encode_filter_properties, _decode_filter_properties\n",
    "```\n",
    "\n",
    "With:\n",
    "\n",
    "```python\n",
    "try:\n",
    "    from _lzma import *\n",
    "    from _lzma import _encode_filter_properties, _decode_filter_properties\n",
    "except ImportError:\n",
    "    from backports.lzma import *\n",
    "    from backports.lzma import _encode_filter_properties, _decode_filter_properties\n",
    "```\n",
    "\n",
    "Save the changes. Now clear outputs in your Notebook and `Run all` again. \n",
    "The issue should resolve.\n",
    "\n",
    "üö® | This is not ideal - the real solution is to find the right Python devcontainer image that has the `lzma` installation done correctly. Until then, this workaround helps us move forward.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. The LIDA Python API\n",
    "\n",
    "- Lida offers a manager class that exposes core functionality of the LIDA system. \n",
    "- This tutorial will show you how to use the manager class to create visualizations based on a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Multiple LLM Backends\n",
    "\n",
    "- LIDA supports multiple LLM backends such as openai, cohere, palm, huggingface etc. \n",
    "- You can switch between backends by setting the text_gen parameter in the Manager class. \n",
    "- By default, LIDA uses the openai backend.  \n",
    "\n",
    "<br/>\n",
    "\n",
    "‚ú® | **For a list of supported models and how to configure them, see the [llmx documentation](https://github.com/victordibia/llmx).**\n",
    "\n",
    "```python\n",
    "from lida import llm\n",
    "\n",
    "text_gen = llm(\"openai\") # for openai\n",
    "text_gen = llm(provider=\"openai\", api_type=\"azure\", api_base=os.environ[\"AZURE_OPENAI_BASE\"], api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],    api_version=\"2023-07-01-preview\") # for azure openai\n",
    "text_gen = llm(\"cohere\") # for cohere\n",
    "text_gen = llm(\"palm\") # for palm\n",
    "text_gen = llm(provider=\"hf\", model=\"uukuguy/speechless-llama2-hermes-orca-platypus-13b\", device_map=\"auto\")\n",
    "\n",
    "lida = Manager(llm=text_gen)\n",
    "```\n",
    "\n",
    "<br/>\n",
    "\n",
    "‚ú® | **Note that you can set llm keys as follows:**\n",
    "\n",
    "```bash\n",
    "export OPENAI_API_KEY=<your key>\n",
    "export COHERE_API_KEY=<your key>\n",
    "# for PaLM\n",
    "export PALM_SERVICE_ACCOUNT_KEY_FILE=<path to gcp service account key file>\n",
    "export PALM_PROJECT_ID=<your gcp project id>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Summarization Methods\n",
    "\n",
    "The summarizer module works takes an `summary_method` argument which determines if the base summary is enriched by an LLM. By default, the `summary_method` argument is set to `default` for a base summary (statistics etc). Set it to `llm` to enrich/annotate the base summary with an llm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Caching\n",
    "Each manager method takes a `textgen_config` argument which is a dictionary that can be used to configure the text generation process (with parameters for model, temperature, max_tokens, topk etc). One of the keys in this dictionary is `use_cache`. If set to `True`, the manager will cache the generated text associated with that method. Use for speedup and to avoid hitting API limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install lida \n",
    "# !pip install lida[infographics] # for infographics support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lida import Manager, TextGenerationConfig , llm  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summarize Data, Generate Goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lida = Manager(text_gen = llm(\"openai\", api_key=None)) # !! api key\n",
    "textgen_config = TextGenerationConfig(n=1, temperature=0.5, model=\"gpt-3.5-turbo-0301\", use_cache=True)\n",
    "\n",
    "summary = lida.summarize(\"https://raw.githubusercontent.com/uwdata/draco/master/data/cars.csv\", summary_method=\"default\", textgen_config=textgen_config)  \n",
    "goals = lida.goals(summary, n=2, textgen_config=textgen_config)\n",
    "\n",
    "for goal in goals:\n",
    "    display(goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goals can also be based on a persona \n",
    "persona = \"a mechanic who wants to buy a car that is cheap but has good gas mileage\"\n",
    "personal_goals = lida.goals(summary, n=2, persona=persona, textgen_config=textgen_config)\n",
    "for goal in personal_goals:\n",
    "    display(goal)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Generate Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "library = \"seaborn\"\n",
    "textgen_config = TextGenerationConfig(n=1, temperature=0.2, use_cache=True)\n",
    "charts = lida.visualize(summary=summary, goal=goals[i], textgen_config=textgen_config, library=library)  \n",
    "charts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Generate visualization via a \"user query\"   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"What is the average price of cars by type?\"\n",
    "textgen_config = TextGenerationConfig(n=1, temperature=0.2, use_cache=True)\n",
    "charts = lida.visualize(summary=summary, goal=user_query, textgen_config=textgen_config)  \n",
    "charts[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. VizOps\n",
    "\n",
    "Given that LIDA represents visualizations as code,\n",
    "the VISGENERATOR also implements submodules\n",
    "to perform operations on this representation. \n",
    "\n",
    "This includes \n",
    "- **Natural language based visualization refinement**: Provides a conversational api to iteratively\n",
    "4Execution in a sandbox environment is recommended.\n",
    "refine generated code (e.g., translate chart t hindi\n",
    ". . . zoom in by 50% etc) which can then be executed to generate new visualizations.\n",
    "- **Visualization explanations and accessibility**:\n",
    "Generates natural language explanations (valuable\n",
    "for debugging and sensemaking) as well as accessibility descriptions (valuable for supporting users\n",
    "with visual impairments).\n",
    "\n",
    "- **Visualization code self-evaluation and repair**:\n",
    "Applies an LLM to self-evaluate generated code on\n",
    "multiple dimensions (see section 4.1.2).\n",
    "\n",
    "- **Visualization recommendation**: Given some context (goals, or an existing visualization), recommend additional visualizations to the user (e.g., for\n",
    "comparison, or to provide additional perspectives).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Natural language based visualization refinement \n",
    "\n",
    "Given some code, modify it based on natural language instructions. This yields a new code snippet that can be executed to generate a new visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = charts[0].code\n",
    "textgen_config = TextGenerationConfig(n=1, temperature=0, use_cache=True)\n",
    "instructions = [\"make the chart height and width equal\", \"change the color of the chart to red\", \"translate the chart to spanish\"]\n",
    "edited_charts = lida.edit(code=code,  summary=summary, instructions=instructions, library=library, textgen_config=textgen_config)\n",
    "edited_charts[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Visualization explanations and accessibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanations = lida.explain(code=code, library=library, textgen_config=textgen_config) \n",
    "for row in explanations[0]:\n",
    "    print(row[\"section\"],\" ** \", row[\"explanation\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Visualization code self-evaluation and repair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations = lida.evaluate(code=code,  goal=goals[i], textgen_config=textgen_config, library=library)[0] \n",
    "for eval in evaluations:\n",
    "    print(eval[\"dimension\"], \"Score\" ,eval[\"score\"], \"/ 10\")\n",
    "    print(\"\\t\", eval[\"rationale\"][:200])\n",
    "    print(\"\\t**********************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textgen_config = TextGenerationConfig(n=2, temperature=0.2, use_cache=True)\n",
    "recommended_charts =  lida.recommend(code=code, summary=summary, n=2,  textgen_config=textgen_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Recommended {len(recommended_charts)} charts\")\n",
    "for chart in recommended_charts:\n",
    "    display(chart) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infographics (Beta)\n",
    "\n",
    "- Explores using LIDA to generate infographics from an existing visualization \n",
    "- Uses the `peacasso` package, and loads open source stable diffusion models \n",
    "- You will need to run `pip install lida[infographics]` to install the required dependencies.\n",
    "- Currently work in progress (work being done to post process infographics with chart axis and title overlays from the original visualization, add presets for different infographic styles, and add more stable diffusion models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install lida[infographics] \n",
    "# ensure you have a GPU runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üö® | Uncomment below to try it out only if you have access to \n",
    "#      a GPU Runtime in your GitHub Codespaces or Docker Desktop\n",
    "\n",
    "# infographics = lida.infographics(visualization = edited_charts[0].raster, n=1, style_prompt=\"pastel art, green pearly rain drops, highly detailed, no blur, white background\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üö® | Uncomment below to try it out only if you have access to \n",
    "#      a GPU Runtime in your GitHub Codespaces or Docker Desktop\n",
    "#      and successfully ran the previous cell\n",
    "from lida.utils import plot_raster\n",
    "# plot_raster([edited_charts[0].raster, infographics[\"images\"][0]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "189101fc34b85ec7417252a331b6b3ef556b71030ac1f6fe00bfbe1409305460"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
